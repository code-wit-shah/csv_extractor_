{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5XBJggBXlLn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96WHjtESggme",
    "outputId": "461c0ba3-bd0c-4382-ad05-c8bbf26d99e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form Field: \n",
      "Consigner : GEM Imports Limited\n",
      "Consigner Street : 2 Athena Way, Hoyland, Barnsley, S74 0FQ\n",
      "Consigner id: GB113484336000\n",
      "Consigner Vat: 113 484 336\n",
      "Consignee : Cutglass - Halloween Gore Store GmBH\n",
      "Consignee Street: Gewerbstr 15 Lansham 85652\n",
      "Consignee Country: Germany \n",
      "Consignee id: DE3489817\n",
      "Reference no ucr: CH003\n",
      "H_Country_of_origin: CN\n",
      "H-total gross mass: 913\n",
      "H-total packages: 4\n",
      "H_Packgae_type: PX\n",
      "H-Total Amount: 5,825.45\n",
      "Table Data: \n",
      "   Supplier Product Code                                        Description  \\\n",
      "19             GIF4698OB                    Essential Makeup Brush Set 6pcs   \n",
      "20               HAL0891                           Halloween Pumpkin Bucket   \n",
      "21               HAL0900                 Halloween Cobweb Party Basket 25cm   \n",
      "22               HAL0908                     Pumpkin Tealight Candle Holder   \n",
      "23             HAL3032OB                                    Ghost Light PDQ   \n",
      "24               HAL3735                            Googly Eyes Plastic Cup   \n",
      "25               HAL5391                        Black Paper Bat Backdrop 2m   \n",
      "26               HAL5417                            Bat Window Stickers 2pk   \n",
      "27             HAL5429OB              Halloween Haunted Home Plaque 40x36cm   \n",
      "28             HAL5453OB               Halloween Cauldron Fragranced Candle   \n",
      "29             HAL5485OB                           Halloween Skull Ash Tray   \n",
      "30             HAL5493OB     Halloween Cement Potion Bottle Decoration 15cm   \n",
      "31             HAL5502OB   Halloween Wipe Clean Tablecloth 132x178cm - Kids   \n",
      "32               HAL5510                      Halloween Strobe Light 12.5cm   \n",
      "33             HAL5511OB                         Black Glitter Bat Headband   \n",
      "34             HAL6864OB                         Halloween Web Table Runner   \n",
      "35               HAL6910       Halloween Squeeze Pumpkin Toy with Beads PDQ   \n",
      "36             HAL8288OB                           Spooky Door Curtain 1.8M   \n",
      "37               HAL8292               Spooky Foil Hanging Decorations 10pk   \n",
      "38             HAL8293OB                  Spooky Hanging Witch Hats 8pk PDQ   \n",
      "39             SUM6800OB                 Pineapple Tumbler with Straw 250ml   \n",
      "40               XMA1762                                Christmas Santa Hat   \n",
      "41               XMA4200                                  Elf Shoe Headband   \n",
      "42             HAL3829OB                 Pumpkin Glass Jar with Straw 350ml   \n",
      "43             HAL5501OB  Halloween Wipe Clean Tablecloth 132x178cm - Ad...   \n",
      "44             HAL6860OB  Halloween Embossed Tombstone Shaped Paper Plat...   \n",
      "45               HAL1335                          Halloween Devil's Trident   \n",
      "\n",
      "    Qty Carton Qty    Price Nett Value     VAT   TOTAL Commodity Codes  \\\n",
      "19   72           3  2.8333     204.00   40.80  244.80      9603298000   \n",
      "20  360          15  0.4983     179.39   35.88  215.27      9505900000   \n",
      "21  480          20    0.46     220.80   44.16  264.96      9505900000   \n",
      "22  192           8    0.62     119.04   23.81  142.85      9505900000   \n",
      "23  288          12    0.62     178.56   35.71  214.27      9405423990   \n",
      "24  360          15    0.54     194.40   38.88  233.28      3926909700   \n",
      "25  240          10    0.85     204.00   40.80  244.80      4819200000   \n",
      "26  252           7    0.46     115.92   23.18  139.10      9505900000   \n",
      "27  120           5     0.9     108.00   21.60  129.60      9505900000   \n",
      "28  240          10     1.1     264.00   52.80  316.80      3406000000   \n",
      "29   96           4     0.9      86.40   17.28  103.68      9505900000   \n",
      "30  192           8     0.9     172.80   34.56  207.36      6810990000   \n",
      "31   96           4     1.5     144.00   28.80  172.80      9505900000   \n",
      "32  288          24    2.25     648.00  129.60  777.60      9405423990   \n",
      "33  240          10    0.58     139.20   27.84  167.04      9505900000   \n",
      "34  240          10    0.75     180.00   36.00  216.00      9505900000   \n",
      "35  480          20    0.46     220.80   44.16  264.96      9505900000   \n",
      "36  240          20    1.25     300.00   60.00  360.00      3926909790   \n",
      "37  144           6    0.56      80.64   16.13   96.77      9505900000   \n",
      "38  240          10  1.4167     340.01   68.00  408.01      9505900000   \n",
      "39  180          10  0.9944     178.99   35.80  214.79      3926909700   \n",
      "40  240          10    0.52     124.80   24.96  149.76      9505109000   \n",
      "41  120           5     0.7      84.00   16.80  100.80      9505109000   \n",
      "42   96           4    0.65      62.40   12.48   74.88      7013100000   \n",
      "43   96           4    1.65     158.40   31.68  190.08      9505900000   \n",
      "44   72           3     0.5      36.00    7.20   43.20      4823699000   \n",
      "45  240          10  0.4583     109.99   22.00  131.99      9503008190   \n",
      "\n",
      "   Package Type Reference Number  \n",
      "19          CTN            CH003  \n",
      "20          CTN            CH003  \n",
      "21          CTN            CH003  \n",
      "22          CTN            CH003  \n",
      "23          CTN            CH003  \n",
      "24          CTN            CH003  \n",
      "25          CTN            CH003  \n",
      "26          CTN            CH003  \n",
      "27          CTN            CH003  \n",
      "28          CTN            CH003  \n",
      "29          CTN            CH003  \n",
      "30          CTN            CH003  \n",
      "31          CTN            CH003  \n",
      "32          CTN            CH003  \n",
      "33          CTN            CH003  \n",
      "34          CTN            CH003  \n",
      "35          CTN            CH003  \n",
      "36          CTN            CH003  \n",
      "37          CTN            CH003  \n",
      "38          CTN            CH003  \n",
      "39          CTN            CH003  \n",
      "40          CTN            CH003  \n",
      "41          CTN            CH003  \n",
      "42          CTN            CH003  \n",
      "43          CTN            CH003  \n",
      "44          CTN            CH003  \n",
      "45          CTN            CH003  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tables_from_csv(file_path):\n",
    "    # Load the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify rows where the percentage of non-null values is greater than 70%\n",
    "    non_null_counts = df.notna().sum(axis=1)\n",
    "    total_columns = df.shape[1]\n",
    "    non_null_percentage = (non_null_counts / total_columns) * 100\n",
    "    rows_to_extract = df[non_null_percentage > 70]\n",
    "    remaining_rows = df[non_null_percentage <= 70]  # Separate the remaining rows\n",
    "\n",
    "    # Check if any rows were extracted\n",
    "    if rows_to_extract.empty:\n",
    "        print(\"No rows with more than 70% non-null values found.\")\n",
    "        return pd.DataFrame(), remaining_rows\n",
    "\n",
    "    # Set the first row of the extracted rows as the header\n",
    "    rows_to_extract.columns = rows_to_extract.iloc[0]  # Set the first row as header\n",
    "    rows_to_extract = rows_to_extract[1:]  # Remove the first row from the data\n",
    "\n",
    "    # Rename columns with NaN names\n",
    "    rows_to_extract.columns = [\n",
    "        f\"Unnamed{i+1}\" if pd.isna(col) else col\n",
    "        for i, col in enumerate(rows_to_extract.columns)\n",
    "    ]\n",
    "\n",
    "    # Ensure unique column names by appending a suffix to duplicates\n",
    "    columns = pd.Series(rows_to_extract.columns)\n",
    "    for dup in columns[columns.duplicated()].unique():\n",
    "        # Append a number to duplicate column names\n",
    "        columns[columns[columns == dup].index.values.tolist()] = [\n",
    "            f\"{dup}_{i+1}\" if i != 0 else dup\n",
    "            for i in range(sum(columns == dup))\n",
    "        ]\n",
    "    rows_to_extract.columns = columns  # Update the DataFrame columns\n",
    "\n",
    "    # Define possible package type keywords\n",
    "    package_type_keywords = ['CTNS', 'QTN', 'Pellate', 'Boxes', 'Euro Pellate', 'Bags', 'Cases', 'Carton']\n",
    "\n",
    "    # Check each row for package type keywords and populate \"Package Type\" column\n",
    "    rows_to_extract['Package Type'] = rows_to_extract.apply(\n",
    "        lambda row: next(\n",
    "            (keyword for keyword in package_type_keywords if keyword in row.to_string()),\n",
    "            None\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Clean up \"Â£\" symbols from numeric values\n",
    "    rows_to_extract = rows_to_extract.applymap(\n",
    "        lambda x: str(x).replace(\"Â£\", \"\").strip() if isinstance(x, str) and \"Â£\" in x else x\n",
    "    )\n",
    "\n",
    "    return rows_to_extract, remaining_rows\n",
    "\n",
    "# Replace with your actual file path\n",
    "file_path = '/content/GEM IMPORTS LTD.csv'\n",
    "\n",
    "# Call the function\n",
    "extracted_rows, remaining_rows = extract_tables_from_csv(file_path)\n",
    "data = remaining_rows\n",
    "results = []\n",
    "\n",
    "# Loop through the DataFrame rows (assuming 'data' is your DataFrame)\n",
    "for index, row in data.iterrows():\n",
    "    for col_index, cell in enumerate(row):\n",
    "        if isinstance(cell, str) and \"Invoice Number:\" in cell:\n",
    "            # Get the two right cells\n",
    "            if col_index + 2 < len(row):\n",
    "                # Extract the next two cells and filter out empty or NaN values\n",
    "                result = [value for value in row[col_index + 1: col_index + 3] if pd.notna(value) and value != \"\"]\n",
    "                if result:  # Only append if there are non-empty values\n",
    "                    results.append(result)\n",
    "\n",
    "# Assuming 'extracted_rows' is already created with other columns\n",
    "# Handle case where results' length might not match extracted_rows length\n",
    "if len(results) > 0:\n",
    "    reference_number = results[0][0]  # Take the first reference number from the results\n",
    "    extracted_rows['Reference Number'] = [reference_number] * len(extracted_rows)\n",
    "else:\n",
    "    # If no reference numbers found, set as None or empty string\n",
    "    extracted_rows['Reference Number'] = [None] * len(extracted_rows)\n",
    "\n",
    "# Map 'Carton' to 'CTN' in the 'Package Type' column\n",
    "extracted_rows['Package Type'] = extracted_rows['Package Type'].apply(\n",
    "    lambda x: 'CTN' if x == 'Carton' else x\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data =remaining_rows\n",
    "print(f\"Form Field: {''}\")\n",
    "# Extract Consigner Name and Street (with regex)\n",
    "consigner_name_and_street = remaining_rows.applymap(lambda x: x if pd.notnull(x) and bool(pd.Series(x).str.contains(r'\\bHoyland\\b', regex=True).iloc[0]) else None)\n",
    "consigner_name_and_street.dropna(how='all', inplace=True)\n",
    "\n",
    "# Print Consigner Name and Street\n",
    "for cell in consigner_name_and_street.values.flatten():\n",
    "    if pd.notna(cell):\n",
    "        parts = cell.split(',', 1)\n",
    "        consigner_name = parts[0].strip()\n",
    "        consignee_street_name = parts[1].strip() if len(parts) > 1 else \"N/A\"\n",
    "        print(f\"Consigner : {consigner_name}\\nConsigner Street : {consignee_street_name}\")\n",
    "# Function to extract GEM EORI or CUTGLASS EORI\n",
    "def extract_eori_value(text, eori_type):\n",
    "    match = re.search(f'{eori_type} EORI\\s+(\\S+)', str(text))\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Extract Consigner EORI\n",
    "consigner_eori_values = remaining_rows.applymap(lambda x: extract_eori_value(x, 'GEM'))\n",
    "consigner_eori_values.dropna(how='all', inplace=True)\n",
    "consigner_eori_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Print Consigner EORI\n",
    "for value in consigner_eori_values.values.flatten():\n",
    "    if pd.notna(value):\n",
    "        print(f\"Consigner id: {value}\")\n",
    "# Extract VAT Number (Consigner VAT)\n",
    "def extract_vat_number(text):\n",
    "    match = re.search(r'Vat No:\\s+(\\d+(\\s\\d+)*)', str(text))\n",
    "    return match.group(1).replace(\" \", \" \") if match else None\n",
    "\n",
    "vat_values = remaining_rows.applymap(extract_vat_number)\n",
    "vat_values.dropna(how='all', inplace=True)\n",
    "vat_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Print VAT Number\n",
    "for value in vat_values.values.flatten():\n",
    "    if pd.notna(value):\n",
    "        print(f\"Consigner Vat: {value}\")\n",
    "\n",
    "        for i, row in data.iterrows():\n",
    "            if 'Invoice To:' in str(row[0]):  # assuming 'Invoice To:' is in the first column (adjust if necessary)\n",
    "                # Extract the next 4 rows (below 'Invoice To:')\n",
    "                consignee_data = data.iloc[i+1:i+6, 0].tolist()  # Adjust the column index if needed\n",
    "\n",
    "                # Assign values to respective fields\n",
    "                consignee_name = consignee_data[0]  # Consignee name is in the first element\n",
    "                consignee_street = \" \".join(consignee_data[1:4])  # Join street address parts into one string\n",
    "                consignee_country = consignee_data[4]  # Country is in the fifth element\n",
    "\n",
    "                # Print the extracted information\n",
    "                print(f\"Consignee : {consignee_name}\")\n",
    "                print(f\"Consignee Street: {consignee_street}\")  # Now street address will print without brackets\n",
    "                print(f\"Consignee Country: {consignee_country}\")\n",
    "\n",
    "# Extract Consignee EORI\n",
    "consignee_eori_values = remaining_rows.applymap(lambda x: extract_eori_value(x, 'CUTGLASS'))\n",
    "consignee_eori_values.dropna(how='all', inplace=True)\n",
    "consignee_eori_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Print Consignee EORI\n",
    "for value in consignee_eori_values.values.flatten():\n",
    "    if pd.notna(value):\n",
    "        print(f\"Consignee id: {value}\")\n",
    "\n",
    "\n",
    "# Extract Invoice Number\n",
    "invoice_numbers = []\n",
    "for index, row in remaining_rows.iterrows():\n",
    "    for col_index, cell in enumerate(row):\n",
    "        if isinstance(cell, str) and \"Invoice Number:\" in cell:\n",
    "            if col_index + 2 < len(row):\n",
    "                result = [value for value in row[col_index + 1: col_index + 3] if pd.notna(value) and value != \"\"]\n",
    "                if result:\n",
    "                    invoice_numbers.append(result)\n",
    "\n",
    "# Print Invoice Numbers\n",
    "for res in invoice_numbers:\n",
    "    print(f\"Reference no ucr: {res[0]}\")\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to extract all words after 'Origin' and map \"China\" to \"CN\"\n",
    "def extract_and_map_text(text):\n",
    "    # Search for variations of the keyword and extract everything after 'Origin'\n",
    "    match = re.search(r'Origin\\s+(\\S+)(.*)', str(text))\n",
    "    if match:\n",
    "        extracted_text = match.group(2).strip()  # Extract everything after 'Origin'\n",
    "        # Map \"China\" or similar values to \"CN\"\n",
    "        if \"China\" in extracted_text:\n",
    "            return \"CN\"\n",
    "        return extracted_text\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "# Apply the function across all cells in the DataFrame\n",
    "remaining_text_values = data.applymap(extract_and_map_text)\n",
    "\n",
    "# Drop rows and columns that do not contain relevant data (optional)\n",
    "remaining_text_values.dropna(how='all', inplace=True)\n",
    "remaining_text_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a simple list of values and print without index and column names\n",
    "remaining_text_values_flat = remaining_text_values.values.flatten()\n",
    "for value in remaining_text_values_flat:\n",
    "    if pd.notna(value):  # Only print non-null values\n",
    "        print(f\"H_Country_of_origin: {value}\")\n",
    "\n",
    "\n",
    "# Extract Gross Weight (Total Gross Mass)\n",
    "def extract_gross_weight(text):\n",
    "    match = re.search(r'Gross Weight\\s+(\\S+)', str(text))\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "gross_weight_values = remaining_rows.applymap(extract_gross_weight)\n",
    "gross_weight_values.dropna(how='all', inplace=True)\n",
    "gross_weight_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Print Gross Weight\n",
    "for value in gross_weight_values.values.flatten():\n",
    "    if pd.notna(value):\n",
    "        print(f\"H-total gross mass: {value}\")\n",
    "\n",
    "# Extract Pallets (Total Package Quantity)\n",
    "def extract_pallets(text):\n",
    "    match = re.search(r'Pallets\\s+(\\S+)', str(text))\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "pallets_values = remaining_rows.applymap(extract_pallets)\n",
    "pallets_values.dropna(how='all', inplace=True)\n",
    "pallets_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Print Pallets (Total Package Quantity)\n",
    "for values in pallets_values.values.flatten():\n",
    "    if pd.notna(values):\n",
    "        print(f\"H-total packages: {values}\")\n",
    "\n",
    "# Function to extract all words after 'Total Pallets 4' and map 'pallets' to 'PX'\n",
    "def extract_remaining_text(text):\n",
    "    # Search for the pattern \"Total Pallets 4\" and extract everything after it\n",
    "    match = re.search(r'Total Pallets 4\\s+(\\S.*)', str(text))\n",
    "    if match:\n",
    "        extracted_text = match.group(1).strip()\n",
    "        # Map 'pallets' to 'PX' in the extracted text\n",
    "        mapped_text = re.sub(r'\\bpallets\\b', 'PX', extracted_text, flags=re.IGNORECASE)\n",
    "        return mapped_text\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "# Apply the function across all cells in the DataFrame\n",
    "remaining_text_values = data.applymap(extract_remaining_text)\n",
    "\n",
    "# Drop rows and columns that do not contain relevant data (optional)\n",
    "remaining_text_values.dropna(how='all', inplace=True)\n",
    "remaining_text_values.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Convert the DataFrame to a simple list of values and print without index and column names\n",
    "remaining_text_values_flat = remaining_text_values.values.flatten()\n",
    "for value in remaining_text_values_flat:\n",
    "    if pd.notna(value):  # Only print non-null values\n",
    "        print(f\"H_Packgae_type: {value}\")\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through the dataframe rows\n",
    "for index, row in data.iterrows():\n",
    "    for col_index, cell in enumerate(row):\n",
    "        if isinstance(cell, str) and \"Grand Total:\" in cell:\n",
    "            # Get all cells to the right of \"Grand Total:\"\n",
    "            right_cells = row[col_index + 1:]\n",
    "            # Find the last non-empty value\n",
    "            last_value = right_cells.dropna().iloc[-1] if not right_cells.dropna().empty else None\n",
    "            if last_value is not None:\n",
    "                # Remove 'Â£' if present and append the cleaned value\n",
    "                results.append(str(last_value).replace(\"Â£\", \"\").strip())\n",
    "\n",
    "# Output the results\n",
    "for res in results:\n",
    "    print(f\"H-Total Amount: {res}\")\n",
    "    print(f\"Table Data: {''}\")\n",
    "    print(extracted_rows)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02YNvRYJcZro",
    "outputId": "f59288c6-3064-4f6f-85a6-7e881c1083f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved as GEM IMPORTS LTD.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Example: get the file name dynamically (replace this part with how you get the actual file name) # Replace with actual file path\n",
    "file_name = os.path.splitext(os.path.basename(file_path))[0]  # Extract file name without extension\n",
    "\n",
    "# Initialize header JSON\n",
    "header_json = []\n",
    "\n",
    "# Example consignor and consignee details (replace with your actual extracted values)\n",
    "consignor_details = {\n",
    "    \"Consignor Name\": consigner_name,\n",
    "    \"Consignor Street\": consignee_street_name,\n",
    "    \"Consignor EORI\": next(iter(consigner_eori_values.values.flatten()), None),\n",
    "    \"Consignor VAT\": next(iter(vat_values.values.flatten()), None),\n",
    "}\n",
    "\n",
    "consignee_details = {\n",
    "    \"Consignee Name\": consignee_name,\n",
    "    \"Consignee Street\": consignee_street,\n",
    "    \"Consignee Country\": consignee_country,\n",
    "    \"Consignee EORI\": next(iter(consignee_eori_values.values.flatten()), None),\n",
    "}\n",
    "\n",
    "# Add consignor details to JSON\n",
    "for key, value in consignor_details.items():\n",
    "    header_json.append({\"key\": {\"key_text\": key}, \"value\": {\"value_text\": value}})\n",
    "\n",
    "# Add consignee details to JSON\n",
    "for key, value in consignee_details.items():\n",
    "    header_json.append({\"key\": {\"key_text\": key}, \"value\": {\"value_text\": value}})\n",
    "\n",
    "# Example dynamic fields (replace with your actual extracted values)\n",
    "dynamic_fields = [\n",
    "    {\"key_text\": \"Reference Number UCR / Invoice Number\", \"value_text\": extracted_rows['Reference Number'].iloc[0] if not extracted_rows.empty else ''},\n",
    "    {\"key_text\": \"H-package type\", \"value_text\": extracted_rows['Package Type'].iloc[0] if not extracted_rows.empty else ''},\n",
    "    {\"key_text\": \"H-Total Packages\", \"value_text\": values},  # Replace with your actual value\n",
    "    {\"key_text\": \"H-Total Gross Mass\", \"value_text\": next(iter(gross_weight_values.values.flatten()), None)},\n",
    "    {\"key_text\": \"H-Total Amount\", \"value_text\": results[0] if results else ''},\n",
    "]\n",
    "\n",
    "# Add dynamic fields to JSON\n",
    "for field in dynamic_fields:\n",
    "    header_json.append({\"key\": {\"key_text\": field['key_text']}, \"value\": {\"value_text\": field['value_text']}})\n",
    "\n",
    "# Prepare table_data (replace with actual logic to generate table data from DataFrame)\n",
    "table_json = []\n",
    "\n",
    "# Reset the index to start from 0 if necessary\n",
    "extracted_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add the header to the table JSON output\n",
    "for col_index, column in enumerate(extracted_rows.columns):\n",
    "    table_json.append({\n",
    "        \"row\": 0,  # Row index for header is 0\n",
    "        \"column\": col_index,\n",
    "        \"text\": str(column)  # Column name as text\n",
    "    })\n",
    "\n",
    "# Iterate over each row and column in the DataFrame (data starts from row 1)\n",
    "for row_index, row in extracted_rows.iterrows():\n",
    "    for col_index, cell in enumerate(row):\n",
    "        table_json.append({\n",
    "            \"row\": row_index + 1,  # Data rows start from index 1\n",
    "            \"column\": col_index,\n",
    "            \"text\": str(cell)  # Cell content\n",
    "        })\n",
    "\n",
    "# Combine everything into the final JSON structure\n",
    "final_json = {\n",
    "    file_name: {  # Use the dynamic file name here\n",
    "        \"resulting_data\": {\n",
    "            \"form_fields\": header_json,  # Include all form fields\n",
    "            \"table_data\": table_json     # Include table data\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the final JSON to a file\n",
    "output_file_path = \"GEM IMPORTS LTD.json\"\n",
    "with open(output_file_path, \"w\") as json_file:\n",
    "    json.dump(final_json, json_file, indent=4)\n",
    "\n",
    "print(f\"JSON file saved as {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
